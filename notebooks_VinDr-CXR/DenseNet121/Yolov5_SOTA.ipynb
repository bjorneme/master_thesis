{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14a7306b4210>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "EXTRACTED_PATH = '/cluster/home/bjorneme/projects/Data/vinbigdata-chest-xray-abnormalities-detection-extracted'\n",
    "train_csv = os.path.join(EXTRACTED_PATH, 'train.csv')\n",
    "\n",
    "# Disease labels\n",
    "disease_labels = [\n",
    "    \"Aortic enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n",
    "    \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung Opacity\",\n",
    "    \"Nodule/Mass\", \"Other lesion\", \"Pleural effusion\", \"Pleural thickening\",\n",
    "    \"Pneumothorax\", \"Pulmonary fibrosis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting a DICOM File to a PIL Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dicom_image(path):\n",
    "    ds = pydicom.dcmread(path)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    img = ((img - img.min()) / (img.max() - img.min()) * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Annotations to YOLO Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotation_to_yolo(group, img_size_override=None):\n",
    "    # Size image\n",
    "    img_path = group.iloc[0]['Path']\n",
    "    img_width, img_height = open_dicom_image(img_path).size\n",
    "    \n",
    "    lines = []\n",
    "    for _, row in group.iterrows():\n",
    "        x_min, y_min, x_max, y_max = row[['x_min','y_min','x_max','y_max']]\n",
    "        x_center = ((x_min + x_max) / 2) / img_width\n",
    "        y_center = ((y_min + y_max) / 2) / img_height\n",
    "        box_width = (x_max - x_min) / img_width\n",
    "        box_height = (y_max - y_min) / img_height\n",
    "        lines.append(f\"{int(row['class_id'])} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n",
    "    return img_path, lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(csv_path, image_path, disease_labels):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for d in disease_labels:\n",
    "        df[d] = df['class_name'].str.contains(d).astype(int)\n",
    "    df['No finding'] = df['class_name'].str.contains('No finding').astype(int)\n",
    "    df['Path'] = df['image_id'].apply(lambda x: os.path.join(image_path, 'train', f\"{x}.dicom\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing Dataset Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(df, split_name, base_dir):\n",
    "    for image_id, group in df.groupby('image_id'):\n",
    "        img_path, yolo_lines = convert_annotation_to_yolo(group)\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        ext = os.path.splitext(img_filename)[1].lower()\n",
    "        img_dir = os.path.join(base_dir, \"images\", split_name)\n",
    "        label_dir = os.path.join(base_dir, \"labels\", split_name)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        pil_img = open_dicom_image(img_path)\n",
    "        img_filename = os.path.splitext(img_filename)[0] + \".png\"\n",
    "        pil_img.save(os.path.join(img_dir, img_filename))\n",
    "        \n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "        with open(os.path.join(label_dir, label_filename), \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Processing Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 36096\n",
      "Train images: 3515, Val images: 879\n",
      "Processing training set...\n",
      "Processing validation set...\n"
     ]
    }
   ],
   "source": [
    "df = load_labels(train_csv, EXTRACTED_PATH, disease_labels)\n",
    "df = df[df['class_id'] != 14]\n",
    "print(f\"Train size: {df.shape[0]}\")\n",
    "\n",
    "unique_ids = df['image_id'].unique()\n",
    "train_ids, val_ids = train_test_split(unique_ids, test_size=0.2, random_state=42)\n",
    "train_df, val_df = df[df['image_id'].isin(train_ids)], df[df['image_id'].isin(val_ids)]\n",
    "print(f\"Train images: {len(train_ids)}, Val images: {len(val_ids)}\")\n",
    "\n",
    "base_dir = \"data\"\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(base_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "print(\"Processing training set...\")\n",
    "process_split(train_df, \"train\", base_dir)\n",
    "print(\"Processing validation set...\")\n",
    "process_split(val_df, \"val\", base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the YOLO data YAML file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = {\n",
    "    \"train\": os.path.join(os.getcwd(), base_dir, \"images\", \"train\"),\n",
    "    \"val\": os.path.join(os.getcwd(), base_dir, \"images\", \"val\"),\n",
    "    \"nc\": 14,\n",
    "    \"names\": disease_labels\n",
    "}\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clone YOLOv5 repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"yolov5\"):\n",
    "    os.system(\"git clone https://github.com/ultralytics/yolov5.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython yolov5/train.py --img 1024 --batch 16 --epochs 50 --data data.yaml --weights yolov5s.pt --cache\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/master_thesis/lib/python3.11/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/master_thesis/lib/python3.11/site-packages/IPython/utils/_process_posix.py:125\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msystem\u001b[39m(\u001b[38;5;28mself\u001b[39m, cmd):\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a command in a subshell.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    int : child's exitstatus\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpexpect\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Get likely encoding for the output.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     enc \u001b[38;5;241m=\u001b[39m DEFAULT_ENCODING\n",
      "File \u001b[0;32m~/.conda/envs/master_thesis/lib/python3.11/site-packages/pexpect/__init__.py:81\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Expecter, searcher_re, searcher_string\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# On Unix, these are available at the top level for backwards compatibility\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpty_spawn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spawn, spawnu\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run, runu\n\u001b[1;32m     84\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.9.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/master_thesis/lib/python3.11/site-packages/pexpect/pty_spawn.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignal\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mptyprocess\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mptyprocess\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mptyprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m use_native_pty_fork\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExceptionPexpect, EOF, TIMEOUT\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!python yolov5/train.py --img 1024 --batch 16 --epochs 50 --data data.yaml --weights yolov5s.pt --cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
